{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Necessary Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.load data (TODO: set aside image for test and validation)\n",
    "#2.Define Neural network\n",
    "#3.Define loss function\n",
    "#4.Train network on training data\n",
    "#5.Test network on test data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings; warnings.filterwarnings(action='once')\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os \n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Resizing images\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "#path = r\"C:\\Users\\truon\\Desktop\\ECE\\ECE196\\ML project\\data\\flowers\\\\\"\n",
    "path = \"/Users/zacharyjohnston/Documents/GitHub/flower/Tai/data/flowers\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "def resize():\n",
    "    i=0\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((700,700), Image.ANTIALIAS)\n",
    "            #imResize.save(r\"C:\\Users\\truon\\Desktop\\ECE\\ECE196\\ML project\\data\\subData\\imgRe\\\\\" + str(i) + ' resized.jpg', 'JPEG', quality=90)\n",
    "            imResize.save(\"/Users/zacharyjohnston/Documents/GitHub/flower/Tai/data/subData/imgRe\" + str(i) + ' resized.jpg', 'JPEG', quality=90)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#train_dir = r\"C:\\Users\\truon\\Desktop\\ECE\\ECE196\\ML project\\data\\subData\"\n",
    "train_dir = \"/Users/zacharyjohnston/Documents/GitHub/flower/Tai/data/subData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image preprocessing\n",
    "# https://auth0.com/blog/image-processing-in-python-with-pillow/#Resizing-Images\n",
    "# Resizing images\n",
    "\n",
    "# image = Image.open('demo_image.jpg')\n",
    "# new_image = image.resize((400, 400))\n",
    "# new_image.save('image_400.jpg')\n",
    "\n",
    "# print(image.size) # Output: (1920, 1280)\n",
    "# print(new_image.size) # Output: (400, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomCrop(128, padding_mode=\"reflect\"),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor()\n",
    "])\n",
    "train_ds = ImageFolder(\n",
    "    root=train_dir,\n",
    "    transform = transform_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image process\n",
    "def display(train_dl):\n",
    "    for images,_ in train_dl:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:32], nrow=8).permute(1,2,0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-8256fbea6f06>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-8256fbea6f06>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    class Net(nn.Module)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "class Net(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
